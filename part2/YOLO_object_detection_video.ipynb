{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import edge_detection as edge\n",
    "import lane_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91187acc",
   "metadata": {},
   "source": [
    "#### Loading Yolo weights, and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682b813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'yolov3.weights'\n",
    "config_path = 'yolov3.cfg'\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "names = net.getLayerNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85484186",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_names = [names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479827ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'coco.names'\n",
    "labels = open(labels_path).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c6da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoHandler(vid_dir, vid_res = (1280,720), Debug = False):\n",
    "    # variables to handle video frames\n",
    "    \n",
    "    prev_leftx = None\n",
    "    prev_lefty = None\n",
    "    prev_rightx = None\n",
    "    prev_righty = None   \n",
    "    prev_left_fit = []\n",
    "    prev_right_fit = []\n",
    "\n",
    "    prev_leftx2 = None\n",
    "    prev_lefty2 = None\n",
    "    prev_rightx2 = None\n",
    "    prev_righty2 = None\n",
    "    prev_left_fit2 = []\n",
    "    prev_right_fit2 = []\n",
    "\n",
    "    output_vid_dir = '../output_videos/{}_part2_thresholded.mp4'.format(vid_dir[12:].split('.')[0])\n",
    "    output_frames_per_second = 20.0                                                       \n",
    " \n",
    "    # Load a video\n",
    "    capture = cv2.VideoCapture(vid_dir)\n",
    "\n",
    "    # Create a VideoWriter object so we can save the video output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    result = cv2.VideoWriter(output_vid_dir,fourcc,output_frames_per_second,vid_res)\n",
    "        \n",
    "    while capture.isOpened():\n",
    "        # Capture one frame at a time\n",
    "        success, frame = capture.read() \n",
    "        # Do we have a video frame? If true, proceed.\n",
    "        if success:\n",
    "            # Resize the frame\n",
    "            width = int(frame.shape[1])\n",
    "            height = int(frame.shape[0])\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            # Store the original frame\n",
    "            original_frame = frame.copy()\n",
    "            lane_detecticted_img = lane_modified.lane_detection(original_frame)\n",
    "            lane_detecticted_img = cv2.cvtColor(lane_detecticted_img, cv2.COLOR_BGR2RGB)\n",
    "            (H,W) = lane_detecticted_img.shape[:2]\n",
    "          \n",
    "            blob = cv2.dnn.blobFromImage(lane_detecticted_img, 1/255.0, (416,416), crop=False, swapRB = False)\n",
    "            net.setInput(blob)\n",
    "            # calculate the runtime of the algorithm\n",
    "            start_t = time.time()\n",
    "            layers_output = net.forward(layers_names)\n",
    "            print(\"A forward pass through yolov3 took {}\".format(time.time() - start_t))\n",
    "          \n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            classIDs = []\n",
    "            \n",
    "            for output in layers_output:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "                    \n",
    "                    if(confidence > 0.85):\n",
    "                        box = detection[:4] * np.array([W,H,W,H])\n",
    "                        bx,by,bw,bh = box.astype(\"int\")\n",
    "\n",
    "                        x = int(bx - (bw/2))\n",
    "                        y = int(by - (bh/2))\n",
    "\n",
    "                    \n",
    "                        boxes.append([x,y,int(bw),int(bh)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "                   \n",
    "            \n",
    "            idxs = cv2.dnn.NMSBoxes(boxes,confidences,score_threshold=0.4,nms_threshold=0.6)\n",
    "            \n",
    "            labels_path = 'coco.names'\n",
    "            labels = open(labels_path).read().strip().split(\"\\n\")\n",
    "            if len(idxs) > 0:\n",
    "                for i in idxs.flatten():\n",
    "                    (x,y) = [boxes[i][0],boxes[i][1]]\n",
    "                    (w,h) = [boxes[i][2],boxes[i][3]]\n",
    "    \n",
    "                    cv2.rectangle(lane_detecticted_img,(x,y),(x+w,y+h),(255,165,0),2)\n",
    "                    cv2.putText(lane_detecticted_img,\"{}: {}\".format(labels[classIDs[i]],confidences[i]), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,165,0),2)\n",
    "            \n",
    "            lane_detecticted_img = cv2.cvtColor(lane_detecticted_img, cv2.COLOR_BGR2RGB)\n",
    "            result.write(lane_detecticted_img)\n",
    "            cv2.imshow(\"Frame\", lane_detecticted_img)\n",
    "          \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # No more video frames left\n",
    "        else:\n",
    "            break\n",
    "    # Stop when the video is finished\n",
    "    capture.release()\n",
    "    # Release the video recording\n",
    "    result.release()\n",
    "    # Close all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c015425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "=         TEST Videos           =\n",
      "======================================\n",
      "challenge_video.mp4\t harder_challenge_video.mp4\t project_video.mp4\t \n",
      "======================================\n",
      "Select a Video from the directory(q- quit): project_video.mp4\n",
      "A forward pass through yolov3 took 0.30255985260009766\n",
      "A forward pass through yolov3 took 0.347200870513916\n",
      "A forward pass through yolov3 took 0.3263683319091797\n",
      "A forward pass through yolov3 took 0.29561686515808105\n",
      "A forward pass through yolov3 took 0.2980954647064209\n",
      "A forward pass through yolov3 took 0.3070249557495117\n",
      "======================================\n",
      "=         TEST Videos           =\n",
      "======================================\n",
      "challenge_video.mp4\t harder_challenge_video.mp4\t project_video.mp4\t \n",
      "======================================\n",
      "Select a Video from the directory(q- quit): q\n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    files = os.listdir('../test_videos')\n",
    "    print(\"======================================\")\n",
    "    print(\"=         TEST Videos           =\")\n",
    "    print(\"======================================\")\n",
    "    for i in files:\n",
    "        print('{}\\t '.format(i), end='')\n",
    "        if files.index(i) % 3 == 0 and files.index(i) != 0:\n",
    "            print('\\n')\n",
    "    print(\"\\n======================================\")\n",
    "\n",
    "    # need to select video name with the extension (ex: project_video.mp4)\n",
    "    file = input(\"Select a Video from the directory(q- quit): \").strip()\n",
    "    # quit program\n",
    "    if file == 'q' or file == 'Q':\n",
    "        break\n",
    "    vid = '../test_videos/' + file\n",
    "    videoHandler(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe709cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
